{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings\n",
    "def get_embedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "# convert row to JSON\n",
    "def row_to_json(row):\n",
    "    row_dict = row.to_dict()\n",
    "    # Ensure all values are strings\n",
    "    row_dict = {k: str(v) for k, v in row_dict.items()}\n",
    "    \n",
    "    return json.dumps(row_dict)\n",
    "\n",
    "def find_most_similar_rows(row, df2, top_n=3):\n",
    "    # Get the embedding of the specified row in df1\n",
    "    row_embedding = get_embedding(row)\n",
    "    df2_embeddings = np.array(df2['embeddings'].tolist())\n",
    "    \n",
    "    similarities = cosine_similarity([row_embedding], df2_embeddings)[0]\n",
    "    df2['similarity'] = similarities\n",
    "    \n",
    "    # Sort by similarity\n",
    "    most_similar = df2.sort_values(by=['similarity'], ascending=False).head(top_n)\n",
    "    \n",
    "    return most_similar\n",
    "\n",
    "def print_full_json(series):\n",
    "    for item in series:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plmdb = pd.read_excel('PLM-DB.xlsx', na_filter=False, dtype={'PartNumber': str})\n",
    "df_qc = pd.read_excel('QC.xlsx', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filters for QC\n",
    "#...\n",
    "# Pre-filters for PLM-DB\n",
    "\n",
    "# Filter and rename columns\n",
    "#...\n",
    "\n",
    "# Define exclusion lists\n",
    "#...\n",
    "\n",
    "# Filter entries\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a VectorDB from QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'QC_with_embeddings.h5'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df_qc_filtered = pd.read_hdf(file_path, key='qc')\n",
    "else:\n",
    "    df_qc_filtered['json'] = df_qc_filtered.apply(row_to_json, axis=1)\n",
    "    df_qc_filtered['embeddings'] = df_qc_filtered['json'].apply(get_embedding)\n",
    "\n",
    "    # Save embeddings to JSON\n",
    "    df_qc_filtered.to_hdf(file_path, key='qc', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search a Component in PLM-DB by Part Number (PN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plmdb_by_selected_pn = df_plmdb_filtered[df_plmdb_filtered['Part Number (PN)'] == '...']\n",
    "print(plmdb_by_selected_pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the component by its Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = 32\n",
    "selected_row_json = row_to_json(plmdb_by_selected_pn.loc[chosen_index])\n",
    "print('Selected Component:')\n",
    "print(selected_row_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of n similar components from QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_components = find_most_similar_rows(selected_row_json, df_qc_filtered, 200)\n",
    "print_full_json(similar_components['json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Given a Selected Component, identify the matching Similar Components based on the following rules:\n",
    "- Direct Match: Same Part Number (PN), Package Code, SubPackage Code, and Manufacturer.\n",
    "- Similarity Match: Same Package Code, SubPackage Code, and Manufacturer, but PN is different or not mentioned.\n",
    "- Alternative Match: Same Package Code and Manufacturer, but different SubPackage Code.\n",
    "\n",
    "Additional rules:\n",
    "- In the Selected Component, the PN is found in the field 'Part Number (PN)', while in Similar Components, it is either found in the field 'Description' or 'Notes', usually within parenthesis, or not mentioned.\n",
    "- For a Direct Match, the Part Number (PN) of the Selected Component must be exactly equal to the number found in the Similar Components.\n",
    "- Package Codes written like 'AB1234-2', 'A1234', '1234', and '1234-I' are equivalent.\n",
    "- Treat Manufacturers as equivalent if they share the same main brand name, regardless of additional descriptors or variations in wording. \n",
    "\n",
    "Output only a JSON with three keys: 'Direct', 'Similarity', and 'Alternative'. Each maps to a list of indexes of the matching Similar Components.\n",
    "\n",
    "Selected Component: \\\"\"\"\n",
    "{row_to_json(plmdb_by_selected_pn.loc[chosen_index])}\n",
    "\\\"\"\"\n",
    "\n",
    "Similar Components: \\\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "for index, row in similar_components.iterrows():\n",
    "    prompt += f\"Index {index}:{row_to_json(row)}\\n\"\n",
    "\n",
    "prompt += '\"\"\"'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a highly accurate and detail-oriented expert system specialized in cross-referencing electronic components across heterogeneous databases. Always prioritize precision, consistency, adherence to the rules provided, and output results in JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}],\n",
    "    max_tokens=2000,\n",
    "    temperature=0,\n",
    "    top_p=0\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "\n",
    "# Parse JSON response\n",
    "json_pattern = r'\\{.*?\\}'\n",
    "match = re.search(json_pattern, response, re.DOTALL)\n",
    "if match:\n",
    "    parsed_response = json.loads(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SELECTED COMPONENT:')\n",
    "print(row_to_json(df_plmdb.loc[chosen_index]))\n",
    "print('DIRECT QUALIFICATIONS (Same PN, Package, SubPackage, Manufacturer) FOR THE SELECTED COMPONENT:')\n",
    "for i in parsed_response['Direct']:\n",
    "        print(row_to_json(df_qc.loc[i]))\n",
    "print('QUALIFICATIONS BY SIMILARITY (Same Package, Subpackage, and Manufacturer) FOR THE SELECTED COMPONENT:')\n",
    "for i in parsed_response['Similarity']:\n",
    "        print(row_to_json(df_qc.loc[i]))\n",
    "print('POSSIBLE ALTERNATIVE QUALIFICATIONS (Same Package and Manufacturer) RELATIVE TO THE SELECTED COMPONENT:')\n",
    "for i in parsed_response['Alternative']:\n",
    "        print(row_to_json(df_qc.loc[i]))\n",
    "print('OTHER RELEVANT QUALIFICATIONS:')\n",
    "for component in similar_components.head(30).iterrows():\n",
    "        if component[0] not in parsed_response['Direct'] and component[0] not in parsed_response['Similarity'] and component[0] not in parsed_response['Alternative']:\n",
    "                print(row_to_json(df_qc.loc[component[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ground truth\n",
    "gt_direct = pd.read_csv('Direct Qualifications_Ground Truth.csv')\n",
    "gt_sim = pd.read_csv('Qualifications by Similarity_Ground Truth.csv')\n",
    "gt_alt = pd.read_csv('Qualifications Alternative_Ground Truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_numbers = pd.concat([gt_direct['PN'], gt_sim['PN'], gt_alt['PN']]).drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('results.json'):\n",
    "    # If the file exists, load the results from the file\n",
    "    with open('results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    # If the file does not exist, initialize an empty list\n",
    "    results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_number in product_numbers:\n",
    "\n",
    "    if any(product_number in result for result in results):\n",
    "        continue  # Skip this iteration if product_number is already in results\n",
    "\n",
    "    plmdb_by_pns = df_plmdb_filtered[df_plmdb_filtered['Part Number (PN)'] == product_number]\n",
    "\n",
    "    result_for_pn = {}\n",
    "    for i, component in plmdb_by_pns.iterrows():\n",
    "        similar_q = find_most_similar_rows(row_to_json(component), df_qc_filtered, 200)\n",
    "\n",
    "        prompt = f\"\"\"Given a Selected Component, identify the matching Similar Components based on the following rules:\n",
    "- Direct Match: Same Part Number (PN), Package Code, SubPackage Code, and Manufacturer.\n",
    "- Similarity Match: Same Package Code, SubPackage Code, and Manufacturer, but PN is different or not mentioned.\n",
    "- Alternative Match: Same Package Code and Manufacturer, but different SubPackage Code.\n",
    "\n",
    "Additional rules:\n",
    "- In the Selected Component, the PN is found in the field 'Part Number (PN)', while in Similar Components, it is either found in the field 'Description' or 'Notes', usually within parenthesis, or not mentioned.\n",
    "- For a Direct Match, the Part Number (PN) of the Selected Component must be exactly equal to the number found in the Similar Components.\n",
    "- For Package Codes, focus only on the main number. Package Codes written like 'AB1234-2', 'A1234', '1234', and '1234-I' are equivalent.\n",
    "- Treat Manufacturers as equivalent if they share the same main brand name, regardless of additional descriptors or variations in wording. \n",
    "\n",
    "Output only a JSON with three keys: 'Direct', 'Similarity', and 'Alternative'. Each maps to a list of indexes of the matching Similar Components.\n",
    "\n",
    "Selected Component: \\\"\"\"\n",
    "{row_to_json(component)}\n",
    "\\\"\"\"\n",
    "\n",
    "Similar Components:\n",
    "\"\"\"\n",
    "\n",
    "        for index, row in similar_q.iterrows():\n",
    "            prompt += f\"Index {index}:{row_to_json(row)}\\n\"\n",
    "\n",
    "        prompt += '\"\"\"'\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a highly accurate and detail-oriented expert system specialized in cross-referencing electronic components across heterogeneous databases. Always prioritize precision, consistency, adherence to the rules provided, and output results in JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=2000,\n",
    "            temperature=0,\n",
    "            top_p=0\n",
    "        )\n",
    "\n",
    "        #time.sleep(31) # To avoid rate_limit errors\n",
    "\n",
    "        response = response.choices[0].message.content\n",
    "\n",
    "        # Parse JSON response\n",
    "        json_pattern = r'\\{.*?\\}'\n",
    "        match = re.search(json_pattern, response, re.DOTALL)\n",
    "        if match:\n",
    "            parsed_response = json.loads(match.group(0))\n",
    "        else:\n",
    "            print('Error Parsing JSON')\n",
    "\n",
    "        # Substitute index with Q_Number\n",
    "        for key in parsed_response:\n",
    "            parsed_response[key] = [df_qc.loc[i]['Number'] for i in parsed_response[key]]\n",
    "\n",
    "        # Merge with other components of the same PN\n",
    "        for key in parsed_response:\n",
    "            result_for_pn[key] = result_for_pn.get(key, []) + parsed_response.get(key, [])\n",
    "    \n",
    "    results.append({product_number: result_for_pn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'results' list to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives_direct = 0\n",
    "true_positives_sim = 0\n",
    "true_positives_alt = 0\n",
    "\n",
    "# Ground truth and predicted counts\n",
    "direct_qualifications_gt_count = 0\n",
    "sim_qualifications_gt_count = 0\n",
    "alt_qualifications_gt_count = 0\n",
    "\n",
    "direct_qualifications_pred_count = 0\n",
    "sim_qualifications_pred_count = 0\n",
    "alt_qualifications_pred_count = 0\n",
    "\n",
    "all_qualifications_pred_count = 0\n",
    "all_qualifications_gt_count = 0\n",
    "\n",
    "# Initialize Jaccard Scores\n",
    "jaccard_direct = 0\n",
    "jaccard_sim = 0\n",
    "jaccard_alt = 0\n",
    "jaccard_all = 0\n",
    "\n",
    "for component in results:\n",
    "    # Direct qualification\n",
    "    direct_qualifications_pred = list(component.values())[0]['Direct']\n",
    "    direct_qualifications_gt = list(gt_direct[gt_direct['PN'] == list(component.keys())[0]]['QN'])\n",
    "    direct_intersection = len(set(direct_qualifications_pred) & set(direct_qualifications_gt))\n",
    "    direct_union = len(set(direct_qualifications_pred) | set(direct_qualifications_gt))\n",
    "\n",
    "    true_positives_direct += direct_intersection\n",
    "    direct_qualifications_gt_count += len(set(direct_qualifications_gt))\n",
    "    direct_qualifications_pred_count += len(set(direct_qualifications_pred))\n",
    "\n",
    "    # Update Jaccard for Direct\n",
    "    if direct_union > 0:\n",
    "        jaccard_direct += direct_intersection / direct_union\n",
    "    else:\n",
    "        if direct_intersection == 0:\n",
    "            jaccard_direct += 1\n",
    "        else:\n",
    "            jaccard_direct += 0\n",
    "\n",
    "    # Qualification by similarity\n",
    "    sim_qualifications_pred = list(component.values())[0]['Similarity']\n",
    "    sim_qualifications_gt = list(gt_sim[gt_sim['PN'] == list(component.keys())[0]]['QN'])\n",
    "    sim_intersection = len(set(sim_qualifications_pred) & set(sim_qualifications_gt))\n",
    "    sim_union = len(set(sim_qualifications_pred) | set(sim_qualifications_gt))\n",
    "\n",
    "    true_positives_sim += sim_intersection\n",
    "    sim_qualifications_gt_count += len(set(sim_qualifications_gt))\n",
    "    sim_qualifications_pred_count += len(set(sim_qualifications_pred))\n",
    "\n",
    "    # Update Jaccard for similarity\n",
    "    if sim_union > 0:\n",
    "        jaccard_sim += sim_intersection / sim_union\n",
    "    else:\n",
    "        if sim_intersection == 0:\n",
    "            jaccard_sim += 1\n",
    "        else:\n",
    "            jaccard_sim += 0\n",
    "\n",
    "    # Qualification (alternative)\n",
    "    alt_qualifications_pred = list(component.values())[0]['Alternative']\n",
    "    alt_qualifications_gt = list(gt_alt[gt_alt['PN'] == list(component.keys())[0]]['QN'])\n",
    "    alt_intersection = len(set(alt_qualifications_pred) & set(alt_qualifications_gt))\n",
    "    alt_union = len(set(alt_qualifications_pred) | set(alt_qualifications_gt))\n",
    "\n",
    "    true_positives_alt += alt_intersection\n",
    "    alt_qualifications_gt_count += len(set(alt_qualifications_gt))\n",
    "    alt_qualifications_pred_count += len(set(alt_qualifications_pred))\n",
    "\n",
    "    # Update Jaccard for Alternative\n",
    "    if alt_union > 0:\n",
    "        jaccard_alt += alt_intersection / alt_union\n",
    "    else:\n",
    "        if alt_intersection == 0:\n",
    "            jaccard_alt += 1\n",
    "        else:\n",
    "            jaccard_alt += 0\n",
    "\n",
    "    # Compute overall qualifications\n",
    "    all_qualifications_pred = list(set(direct_qualifications_pred) | set(sim_qualifications_pred) | set(alt_qualifications_pred))\n",
    "    all_qualifications_gt = list(set(direct_qualifications_gt) | set(sim_qualifications_gt) | set(alt_qualifications_gt))\n",
    "    all_intersection = len(set(all_qualifications_pred) & set(all_qualifications_gt))\n",
    "    all_union = len(set(all_qualifications_pred) | set(all_qualifications_gt))\n",
    "\n",
    "    # Update overall counts\n",
    "    all_qualifications_pred_count += len(all_qualifications_pred)\n",
    "    all_qualifications_gt_count += len(all_qualifications_gt)\n",
    "\n",
    "    # Update Jaccard for All\n",
    "    if all_union > 0:\n",
    "        jaccard_all += all_intersection / all_union\n",
    "    else:\n",
    "        if all_intersection == 0:\n",
    "            jaccard_all += 1\n",
    "        else:\n",
    "            jaccard_all += 0\n",
    "\n",
    "# Calculate overall precision, recall, and F1\n",
    "precision = (true_positives_direct + true_positives_sim + true_positives_alt) / all_qualifications_pred_count\n",
    "recall = (true_positives_direct + true_positives_sim + true_positives_alt) / all_qualifications_gt_count\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Jaccard Scores\n",
    "jaccard_direct /= len(results)\n",
    "jaccard_sim /= len(results)\n",
    "jaccard_alt /= len(results)\n",
    "jaccard_all /= len(results)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1_score)\n",
    "print('Jaccard All:', jaccard_all)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Direct metrics\n",
    "precision_direct = true_positives_direct / direct_qualifications_pred_count\n",
    "recall_direct = true_positives_direct / direct_qualifications_gt_count\n",
    "f1_direct = 2 * (precision_direct * recall_direct) / (precision_direct + recall_direct)\n",
    "\n",
    "print('Precision_direct:', precision_direct)\n",
    "print('Recall_direct:', recall_direct)\n",
    "print('F1-score_direct:', f1_direct)\n",
    "print('Jaccard_direct:', jaccard_direct)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Similarity metrics\n",
    "precision_sim = true_positives_sim / sim_qualifications_pred_count\n",
    "recall_sim = true_positives_sim / sim_qualifications_gt_count\n",
    "f1_sim = 2 * (precision_sim * recall_sim) / (precision_sim + recall_sim)\n",
    "\n",
    "print('Precision_sim:', precision_sim)\n",
    "print('Recall_sim:', recall_sim)\n",
    "print('F1-score_sim:', f1_sim)\n",
    "print('Jaccard_sim:', jaccard_sim)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Alternative metrics\n",
    "precision_alt = true_positives_alt / alt_qualifications_pred_count\n",
    "recall_alt = true_positives_alt / alt_qualifications_gt_count\n",
    "f1_alt = 2 * (precision_alt * recall_alt) / (precision_alt + recall_alt)\n",
    "\n",
    "print('Precision_alt:', precision_alt)\n",
    "print('Recall_salt:', recall_alt)\n",
    "print('F1-score_alt:', f1_alt)\n",
    "print('Jaccard_alt:', jaccard_alt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall within top 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qualifications_gt_count = 0\n",
    "all_qualifications_pred_count = 0\n",
    "for product_number in product_numbers:\n",
    "    plmdb_by_pns = df_plmdb_filtered[df_plmdb_filtered['Part Number (PN)'] == product_number]\n",
    "\n",
    "    similar_q_pn = set()\n",
    "    for i, component in plmdb_by_pns.iterrows():\n",
    "        similar_q = find_most_similar_rows(row_to_json(component), df_qc_filtered, 200).index\n",
    "        similar_q = [df_qc.loc[index]['Number'] for index in similar_q]\n",
    "        similar_q_pn = set(similar_q) | similar_q_pn\n",
    "    \n",
    "    direct_qualifications_gt = list(gt_direct[gt_direct['PN'] == product_number]['QN'])\n",
    "    sim_qualifications_gt = list(gt_sim[gt_sim['PN'] == product_number]['QN'])\n",
    "    alt_qualifications_gt = list(gt_alt[gt_alt['PN'] == product_number]['QN'])\n",
    "    all_qualifications_gt = set(direct_qualifications_gt) | set(sim_qualifications_gt) | set(alt_qualifications_gt)\n",
    "    \n",
    "    all_qualifications_pred = similar_q_pn & all_qualifications_gt\n",
    "\n",
    "    all_qualifications_gt_count += len(all_qualifications_gt)\n",
    "    all_qualifications_pred_count += len(all_qualifications_pred)\n",
    "    \n",
    "print(\"Recall from Top-n Similar:\")  # n = 200\n",
    "print(all_qualifications_pred_count/all_qualifications_gt_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
